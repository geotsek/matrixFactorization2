{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from funk_svd.utils import _timer\n",
    "from funk_svd import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from MovieLens 20M dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MovieLens 20M Dataset Research Paper](\"http://files.grouplens.org/papers/harper-tiis2015.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Unzipping data...\n",
      "\n",
      "CPU times: user 1min 54s, sys: 7.04 s, total: 2min 1s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = fetch_ml_ratings(variant='20m', verbose=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28507</td>\n",
       "      <td>1176</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995-01-09 12:46:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131160</td>\n",
       "      <td>1079</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131160</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131160</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1995-01-09 12:46:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85252</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1996-01-29 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     u_id  i_id  rating           timestamp\n",
       "0   28507  1176     4.0 1995-01-09 12:46:44\n",
       "1  131160  1079     3.0 1995-01-09 12:46:49\n",
       "2  131160    47     5.0 1995-01-09 12:46:49\n",
       "3  131160    21     3.0 1995-01-09 12:46:49\n",
       "4   85252    45     3.0 1996-01-29 01:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>i_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>53930</td>\n",
       "      <td>118706</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>16978</td>\n",
       "      <td>2093</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>89081</td>\n",
       "      <td>55232</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:11:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>89081</td>\n",
       "      <td>52458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-03-31 08:11:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>87586</td>\n",
       "      <td>7151</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2015-03-31 08:40:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           u_id    i_id  rating           timestamp\n",
       "20000258  53930  118706     3.5 2015-03-31 08:00:51\n",
       "20000259  16978    2093     3.5 2015-03-31 08:03:17\n",
       "20000260  89081   55232     3.5 2015-03-31 08:11:26\n",
       "20000261  89081   52458     4.0 2015-03-31 08:11:28\n",
       "20000262  87586    7151     3.5 2015-03-31 08:40:02"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a train/val/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 138,493 different users in the MovieLens20m dataset, each of them having rated at least 20 movies. Let's sample the 4 last ratings per user and randomly split them between validation and test sets. \n",
    "\n",
    "To do so, we need to query our DataFrame for each user and then select their 4 last ratings. With so much users it's naturally quite expensive... hopefully it's possible to parallelize it as iterations are independant, allowing us to save some time (especially if you have good computing ressources). I'm using an Intel Core i7-8565U CPU (4 physical cores) on a 16GB laptop.\n",
    "\n",
    "<img src=\"https://www.dlapiper.com/~/media/images/insights/publications/2015/warning.jpg?la=en&hash=6F2E30889FD9E0B11016A1712E6E583575717C54\" width=\"23\" align=\"left\">\n",
    "\n",
    "&nbsp; If you want to run this notebook with **Windows**, you won't be able to use `multiprocessing.Pool` because it's lacking `fork` method. For simplicity you can just do it sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_timer(text='')\n",
    "def compute_val_test_mask(data, i, n_process, n_rate=4):\n",
    "    val_test_mask = []\n",
    "    users = data['u_id'].unique()\n",
    "    \n",
    "    for u_id in users:\n",
    "        u_subset = data[data['u_id'] == u_id].copy()\n",
    "        val_test_mask += u_subset.iloc[-n_rate:].index.tolist()\n",
    "        \n",
    "    print(f'Process {i} done in', end=' ')\n",
    "    return val_test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 2 done in 1 min and 28 sec\n",
      "Process 5 done in 1 min and 30 sec\n",
      "Process 9 done in 1 min and 30 sec\n",
      "Process 1 done in 1 min and 31 sec\n",
      "Process 6 done in 1 min and 31 sec\n",
      "Process 0 done in 1 min and 32 sec\n",
      "Process 11 done in 1 min and 30 sec\n",
      "Process 4 done in 1 min and 32 sec\n",
      "Process 7 done in 1 min and 31 sec\n",
      "Process 8 done in 1 min and 31 sec\n",
      "Process 3 done in 1 min and 32 sec\n",
      "Process 10 done in 1 min and 32 sec\n"
     ]
    }
   ],
   "source": [
    "users = df['u_id'].unique()\n",
    "\n",
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(users)\n",
    "\n",
    "n_process = 12\n",
    "pool = mp.Pool(processes=n_process)\n",
    "\n",
    "df_splitted = [\n",
    "    df.query('u_id.isin(@users_subset)')\n",
    "    for users_subset in np.array_split(users, n_process)\n",
    "]\n",
    "\n",
    "results = [\n",
    "    pool.apply_async(compute_val_test_mask, args=(data, i, n_process))\n",
    "    for i, data in zip(range(n_process), df_splitted)\n",
    "]\n",
    "\n",
    "results = [p.get() for p in results]\n",
    "val_test_mask = [item for sublist in results for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.drop(val_test_mask)\n",
    "val = df.loc[val_test_mask].sample(frac=0.5, random_state=seed)\n",
    "test = df.loc[val_test_mask].drop(val.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | val_loss: 0.98 - val_rmse: 0.99 - val_mae: 0.78 - took 1.4 sec\n",
      "Epoch 2/100  | val_loss: 0.95 - val_rmse: 0.98 - val_mae: 0.76 - took 0.8 sec\n",
      "Epoch 3/100  | val_loss: 0.94 - val_rmse: 0.97 - val_mae: 0.76 - took 0.8 sec\n",
      "Epoch 4/100  | val_loss: 0.93 - val_rmse: 0.96 - val_mae: 0.75 - took 0.8 sec\n",
      "Epoch 5/100  | val_loss: 0.92 - val_rmse: 0.96 - val_mae: 0.75 - took 0.7 sec\n",
      "Epoch 6/100  | val_loss: 0.91 - val_rmse: 0.95 - val_mae: 0.74 - took 0.7 sec\n",
      "Epoch 7/100  | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.74 - took 0.8 sec\n",
      "Epoch 8/100  | val_loss: 0.90 - val_rmse: 0.95 - val_mae: 0.74 - took 0.7 sec\n",
      "Epoch 9/100  | val_loss: 0.89 - val_rmse: 0.95 - val_mae: 0.74 - took 0.8 sec\n",
      "Epoch 10/100 | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.73 - took 0.8 sec\n",
      "Epoch 11/100 | val_loss: 0.89 - val_rmse: 0.94 - val_mae: 0.73 - took 0.8 sec\n",
      "Epoch 12/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.8 sec\n",
      "Epoch 13/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.7 sec\n",
      "Epoch 14/100 | val_loss: 0.88 - val_rmse: 0.94 - val_mae: 0.73 - took 0.7 sec\n",
      "Epoch 15/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.72 - took 0.8 sec\n",
      "Epoch 16/100 | val_loss: 0.87 - val_rmse: 0.93 - val_mae: 0.72 - took 0.8 sec\n",
      "Epoch 17/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.7 sec\n",
      "Epoch 18/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.8 sec\n",
      "Epoch 19/100 | val_loss: 0.86 - val_rmse: 0.93 - val_mae: 0.72 - took 0.8 sec\n",
      "Epoch 20/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.72 - took 0.8 sec\n",
      "Epoch 21/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.71 - took 0.7 sec\n",
      "Epoch 22/100 | val_loss: 0.85 - val_rmse: 0.92 - val_mae: 0.71 - took 0.7 sec\n",
      "Epoch 23/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.71 - took 0.8 sec\n",
      "Epoch 24/100 | val_loss: 0.84 - val_rmse: 0.92 - val_mae: 0.71 - took 0.8 sec\n",
      "Epoch 25/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.71 - took 0.8 sec\n",
      "Epoch 26/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.71 - took 0.9 sec\n",
      "Epoch 27/100 | val_loss: 0.83 - val_rmse: 0.91 - val_mae: 0.70 - took 0.8 sec\n",
      "Epoch 28/100 | val_loss: 0.82 - val_rmse: 0.91 - val_mae: 0.70 - took 1.0 sec\n",
      "Epoch 29/100 | val_loss: 0.82 - val_rmse: 0.91 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 30/100 | val_loss: 0.82 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 31/100 | val_loss: 0.82 - val_rmse: 0.90 - val_mae: 0.70 - took 1.0 sec\n",
      "Epoch 32/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.70 - took 0.9 sec\n",
      "Epoch 33/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.70 - took 0.8 sec\n",
      "Epoch 34/100 | val_loss: 0.81 - val_rmse: 0.90 - val_mae: 0.69 - took 0.7 sec\n",
      "Epoch 35/100 | val_loss: 0.80 - val_rmse: 0.90 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 36/100 | val_loss: 0.80 - val_rmse: 0.90 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 37/100 | val_loss: 0.80 - val_rmse: 0.89 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 38/100 | val_loss: 0.80 - val_rmse: 0.89 - val_mae: 0.69 - took 0.7 sec\n",
      "Epoch 39/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 40/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 41/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.8 sec\n",
      "Epoch 42/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.69 - took 0.7 sec\n",
      "Epoch 43/100 | val_loss: 0.79 - val_rmse: 0.89 - val_mae: 0.68 - took 0.8 sec\n",
      "Epoch 44/100 | val_loss: 0.78 - val_rmse: 0.89 - val_mae: 0.68 - took 0.8 sec\n",
      "Epoch 45/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.7 sec\n",
      "Epoch 46/100 | val_loss: 0.78 - val_rmse: 0.88 - val_mae: 0.68 - took 0.8 sec\n",
      "\n",
      "Training took 42 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<funk_svd.svd.SVD at 0x7fd25a850240>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(lr=0.001, reg=0.005, n_epochs=100, n_factors=15,\n",
    "          early_stopping=True, shuffle=False, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and compute results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.88\n",
      "Test MAE:  0.68\n",
      "\n",
      "CPU times: user 1.17 s, sys: 184 ms, total: 1.35 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred = svd.predict(test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test['rating'], pred))\n",
    "mae = mean_absolute_error(test['rating'], pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse:.2f}')\n",
    "print(f'Test MAE:  {mae:.2f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format data according Surprise way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 1.36 s, total: 26.5 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "trainset = Dataset.load_from_df(train[['u_id', 'i_id', 'rating']],\n",
    "                               reader=reader).build_full_trainset()\n",
    "\n",
    "testset = Dataset.load_from_df(test[['u_id', 'i_id', 'rating']], reader=reader)\n",
    "testset = testset.construct_testset(testset.raw_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "\n",
      "CPU times: user 10min 40s, sys: 725 ms, total: 10min 40s\n",
      "Wall time: 10min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd = SVD(lr_all=.001, reg_all=0.005, n_epochs=46, n_factors=15, verbose=True)\n",
    "svd.fit(trainset)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set and compute results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.88\n",
      "Test MAE:  0.68\n",
      "\n",
      "CPU times: user 1.84 s, sys: 101 ms, total: 1.94 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred = svd.test(testset)\n",
    "y_true = [p.r_ui for p in pred]\n",
    "y_hat = [p.est for p in pred]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_hat))\n",
    "mae = mean_absolute_error(y_true, y_hat)\n",
    "\n",
    "print(f'Test RMSE: {rmse:.2f}')\n",
    "print(f'Test MAE:  {mae:.2f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy performance is naturally equivalent, difference stands in the computation time, `Numba` allowing us to run more than 10 times faster than with cython.\n",
    "\n",
    "| Movielens 20M | RMSE   | MAE    | Time          |\n",
    "|:--------------|:------:|:------:|--------------:|\n",
    "| Surprise      |  0.88  |  0.68  | 10 min 40 sec |\n",
    "| Funk-svd      |  0.88  |  0.68  |        42 sec |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
